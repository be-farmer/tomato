{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO++OhBuf9bvZQvC1kQOaSs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iez44dB28ace","executionInfo":{"status":"ok","timestamp":1694851619349,"user_tz":-540,"elapsed":566207,"user":{"displayName":"Juwon park","userId":"07019263524807027762"}},"outputId":"31ded9c1-7948-4ea3-d864-0f983a244748"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","2121/2121 [==============================] - 13s 6ms/step - loss: 48060817408.0000 - val_loss: 841556736.0000\n","Epoch 2/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 378083008.0000 - val_loss: 103015368.0000\n","Epoch 3/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 47245828.0000 - val_loss: 15327303.0000\n","Epoch 4/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 5222148.5000 - val_loss: 736363.0625\n","Epoch 5/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 225263.2500 - val_loss: 43814.5938\n","Epoch 6/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 32647.0840 - val_loss: 18543.7598\n","Epoch 7/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 70939.6797 - val_loss: 13957.6260\n","Epoch 8/50\n","2121/2121 [==============================] - 12s 5ms/step - loss: 106488.8516 - val_loss: 7146.4565\n","Epoch 9/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 43894.3047 - val_loss: 18858.6113\n","Epoch 10/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 66208.5078 - val_loss: 1286.2407\n","Epoch 11/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 45585.3672 - val_loss: 1141.8617\n","Epoch 12/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 91322.6875 - val_loss: 1614.6526\n","Epoch 13/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 38415.8281 - val_loss: 881.4800\n","Epoch 14/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 41288.0430 - val_loss: 4581.0581\n","Epoch 15/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 108547.9141 - val_loss: 2771.3130\n","Epoch 16/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 82464.6953 - val_loss: 1990.3055\n","Epoch 17/50\n","2121/2121 [==============================] - 12s 5ms/step - loss: 33046.7461 - val_loss: 3414.7488\n","Epoch 18/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 74211.9688 - val_loss: 1416.1954\n","Epoch 19/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 28507.9688 - val_loss: 1815.0737\n","Epoch 20/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 45044.3789 - val_loss: 512.7279\n","Epoch 21/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 70602.4219 - val_loss: 802.2732\n","Epoch 22/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 95350.3672 - val_loss: 1721.2845\n","Epoch 23/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 124343.2266 - val_loss: 5209.3833\n","Epoch 24/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 25104.8105 - val_loss: 7636.9277\n","Epoch 25/50\n","2121/2121 [==============================] - 12s 5ms/step - loss: 57411.0234 - val_loss: 53485.6719\n","Epoch 26/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 83789.8125 - val_loss: 17936.3340\n","Epoch 27/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 58838.9180 - val_loss: 1365.6931\n","Epoch 28/50\n","2121/2121 [==============================] - 12s 5ms/step - loss: 71079.9141 - val_loss: 483.6947\n","Epoch 29/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 18982.6719 - val_loss: 3614.0120\n","Epoch 30/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 90096.3594 - val_loss: 1543.0353\n","Epoch 31/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 62183.7734 - val_loss: 909.9016\n","Epoch 32/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 63048.2969 - val_loss: 674.2083\n","Epoch 33/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 54049.3594 - val_loss: 2742.1187\n","Epoch 34/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 103937.0234 - val_loss: 16274.6875\n","Epoch 35/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 62670.6367 - val_loss: 612.3229\n","Epoch 36/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 78969.0156 - val_loss: 1405.3187\n","Epoch 37/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 71727.2500 - val_loss: 5727.0674\n","Epoch 38/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 31489.7324 - val_loss: 10130.8428\n","Epoch 39/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 64368.3477 - val_loss: 956.3517\n","Epoch 40/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 132037.8438 - val_loss: 1935.9305\n","Epoch 41/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 134094.3750 - val_loss: 1949.2886\n","Epoch 42/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 81482.4375 - val_loss: 673.2883\n","Epoch 43/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 91858.3906 - val_loss: 445.7037\n","Epoch 44/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 21665.5625 - val_loss: 482.2800\n","Epoch 45/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 68467.2500 - val_loss: 74548.0469\n","Epoch 46/50\n","2121/2121 [==============================] - 12s 6ms/step - loss: 39581.1953 - val_loss: 2280.8601\n","Epoch 47/50\n","2121/2121 [==============================] - 12s 5ms/step - loss: 116774.7969 - val_loss: 10807.7480\n","Epoch 48/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 61863.0586 - val_loss: 1891.6426\n","Epoch 49/50\n","2121/2121 [==============================] - 11s 5ms/step - loss: 109368.2344 - val_loss: 24572.7461\n","Epoch 50/50\n","2121/2121 [==============================] - 12s 5ms/step - loss: 51343.4688 - val_loss: 1088.5743\n","531/531 [==============================] - 1s 2ms/step\n","RMSE: 32.99344570745588\n","R2_score: 0.999999889287462\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 로드\n","data = pd.read_csv(\"2023_smartFarm_AI_hackathon_dataset.csv\")\n","\n","# 필요한 특성 선택\n","selected_features = ['outtrn_cumsum', 'HeatingEnergyUsage_cumsum']\n","X = data[selected_features].values\n","y = data[['outtrn_cumsum', 'HeatingEnergyUsage_cumsum']].values  # 'target_variable'은 예측하려는 대상 변수\n","\n","# 데이터 스케일링\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# 훈련 및 테스트 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# 딥러닝 모델 생성\n","model = Sequential()\n","model.add(Dense(1028, activation='relu', input_dim=X.shape[1]))\n","model.add(Dense(514, activation='relu'))\n","model.add(Dense(2, activation='linear'))  # 선형 활성화 함수를 사용하여 회귀 모델 생성\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='mse')  # 평균 제곱 오차(MSE)를 손실 함수로 사용\n","\n","# 모델 훈련\n","model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n","\n","# Predict 'y' values using the trained model\n","y_pred = model.predict(X_test)\n","\n","\n","\n","# Calculate RMSE between the predictions and actual 'y' values\n","def calculate_rmse(targets, predictions):\n","    \"\"\"\n","    Calculate the Root Mean Squared Error (RMSE) between predicted and target values.\n","\n","    :param predictions: Predicted values.\n","    :type predictions: array-like\n","    :param targets: Target values.\n","    :type targets: array-like\n","    :return: RMSE value.\n","    :rtype: float\n","    \"\"\"\n","    from sklearn.metrics import mean_squared_error\n","    return np.sqrt(mean_squared_error(targets, predictions))\n","\n","\n","# Calculate r2_score between the predictions and actual 'y' values\n","def calculate_R2_score(y_test,y_pred):\n","    from sklearn.metrics import r2_score\n","    return r2_score(y_test, y_pred)\n","\n","\n","rmse = calculate_rmse(y_test, y_pred)\n","r2score = calculate_R2_score(y_test, y_pred)\n","\n","# ------------------------------------------------\n","### OUTPUT ###\n","print(\"RMSE:\", rmse)\n","print(\"R2_score:\", r2score)"]}]}